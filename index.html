<html>
<head>
  <meta content="text/html; charset=utf-8" http-equiv="Content-Type" />
  <title>Mingde Yao (姚明德)</title>
  <meta content="Mingde Yao (姚明德), mdyao.github.io" name="keywords" />
  <style media="screen" type="text/css">
  html, body, div, span, applet, object, iframe, h1, h2, h3, h4, h5, h6, p, blockquote, pre, a, abbr, acronym, address, big, cite, code, del, dfn, em, font, img, ins, kbd, q, s, samp, small, strike, strong, sub, tt, var, dl, dt, dd, ol, ul, li, fieldset, form, label, legend, table, caption, tbody, tfoot, thead, tr, th, td {
  border: 0pt none;
  /* font-family: Lato, sans-serif; */
  font-family: Arial;
  /* font-family: Georgia; */
  font-size: 100%;
  font-style: inherit;
  font-weight: inherit;
  margin: 0pt;
  outline-color: invert;
  outline-style: none;
  outline-width: 0pt;
  padding: 0pt;
  vertical-align: baseline;
}

a {
  color: #043d98;
  text-decoration:none;
}

a:focus, a:hover {
  color: #f09228;
  text-decoration:none;
}



* {
  margin: 0pt;
  padding: 0pt;
}

body {
  position: relative;
  margin: 2em auto 2em auto;
  width: 870px;
  font-family: Open Sans Light, Helvetica, sans-serif;
  font-size: 15px;
  background: #F4F6F6;
}

h2 {
  font-family: Lato, Verdana, Helvetica, sans-serif;
  font-size: 15pt;
  font-weight: 700;
}

h3 {
  font-family: Lato, Verdana, Helvetica, sans-serif;
  font-size: 16px;
  font-weight: 700;
}

strong {
  /* font-family: Arial, Verdana, Helvetica, sans-serif; */
  /* font-size: 13px; */
  font-weight:bold;
}

ul { 
  /* list-style: circle; */
  list-style: disc;
}

img {
  border: none;
}

li {
  padding-bottom: 0.5em;
  margin-left: 1.4em;
}

alert {
  font-family: Arial, Helvetica, sans-serif;
  font-size: 14px;
  font-weight: bold;
  color: #FF0000;
}

em, i {
  font-style:italic;
}

div.section {
  clear: both;
  margin-bottom: 1.2em;
  background: #F4F6F6;
}

div.spanner {
  clear: both;
}

div.paper {
  clear: both;
  margin-top: 0.4em;
  margin-bottom: 0.7em;
  border: 2px solid #ddd;
  background: #fff;
  padding: 0.55em .8em 0.6em .8em;
  border-top-right-radius:10px; 
  border-top-left-radius:10px; 
  border-bottom-left-radius:10px; 
  border-bottom-right-radius:10px;
  line-height: 140%;
}
div.paper2 {
  clear: both;
  margin-top: 0.4em;
  margin-bottom: 0.7em;
  border: 0px solid #ddd;
  background: #fff;
  padding: 0.55em .8em 0.6em .8em;
  border-top-right-radius:10px; 
  border-top-left-radius:10px; 
  border-bottom-left-radius:10px; 
  border-bottom-right-radius:10px;
  line-height: 140%;
}

div.experience {
  /* clear: both; */
  margin-top: 0.4em;
  margin-bottom: 0.7em;
  /* border: 2px solid #ddd; */
  background: #fff;
  padding: 0.55em .8em 0.6em .8em;
  /* border-top-right-radius:10px; 
  border-top-left-radius:10px; 
  border-bottom-left-radius:10px; 
  border-bottom-right-radius:10px; */
  line-height: 140%;
}


div.education {
  /* clear: both; */
  margin-top: 0.4em;
  margin-bottom: 0.7em;
  /* border: 2px solid #ddd; */
  background: #fff;
  padding: 0.55em .8em 0.6em .8em;
  /* border-top-right-radius:10px; 
  border-top-left-radius:10px; 
  border-bottom-left-radius:10px; 
  border-bottom-right-radius:10px; */
  line-height: 140%;
}


div.paper:hover {
    background: #FFFDEE;
    /* background-color: #242d36 ; */
}

div.paper2:hover {
    background: #FFFDEE;
    /* background-color: #242d36 ; */
}
div.bio {
  clear: both;
  margin-top: 0.4em;
  margin-bottom: 0.7em;
  border: 0px solid #ddd;
  background: #fff;
  padding: 0.55em .8em 0.6em .8em;
  border-top-right-radius:10px; 
  border-top-left-radius:10px; 
  border-bottom-left-radius:10px; 
  border-bottom-right-radius:10px;
  line-height: 135%;
}

div.res {
  clear: both;
  margin-top: 0.4em;
  margin-bottom: 0.4em;
  border: 0px solid #ddd;
  background: #fff;
  padding: 0.65em .8em 0.15em .8em;
  border-top-right-radius:10px; 
  border-top-left-radius:10px; 
  border-bottom-left-radius:10px; 
  border-bottom-right-radius:10px;
  line-height: 130%;
}

div.award {
  clear: both;
  margin-top: 0.4em;
  margin-bottom: 0.4em;
  border: 0px solid #ddd;
  background: #fff;
  padding: 0.65em .8em 0.15em .8em;
  border-top-right-radius:10px; 
  border-top-left-radius:10px; 
  border-bottom-left-radius:10px; 
  border-bottom-right-radius:10px;
  line-height: 130%;
}

div.paper div {
  padding-left: 270px;
}

div.experience div {
  padding-left: 200px;
}

div.education div {
  padding-left: 200px;
}

img.paper {
  /* margin-bottom: 0.4em; */
  float: left;
  width: 250px;

}

img.experience {
  /* margin-bottom: 0.4em; */
  padding-top: 10px;
  float: left;
  width: 170px;

}

img.education {
  /* margin-bottom: 0.4em; */
  padding-left: 30px;
  float: left;
  width: 100px;

}

span.blurb {
  font-style:italic;
  display:block;
  margin-top:0.75em;
  margin-bottom:0.5em;
}

pre, code {
  font-family: Open Sans Light, Helvetica, sans-serif;
  font-size: 14px;
  margin: 1em 0;
  padding: 0;
}

    .bot {
  font-size: 14%;
}

   .ptypej {
    display: inline;
    padding: .0em .2em .05em;
    font-size: 85%;
    font-weight: bold;
    line-height: 1;
  background-color: #5cb85c;
    color: #FFFFFF;
    text-align: center;
    white-space: nowrap;
    vertical-align: baseline;
  margin-right: 6px;
}
   .ptypec {
    display: inline;
    padding: .0em .2em .05em;
    font-size: 85%;
    font-weight: bold;
    line-height: 1;
  background-color: #428bca;
    color: #FFFFFF;
    text-align: center;
    white-space: nowrap;
    vertical-align: baseline;
  margin-right: 6px;
}
   .ptypep {
    display: inline;
    padding: .0em .2em .05em;
    font-size: 85%;
    font-weight: bold;
    line-height: 1;
  background-color: #6B6B6B;
    color: #FFFFFF;
    text-align: center;
    white-space: nowrap;
    vertical-align: baseline;
  margin-right: 6px;
}
/* navigation */
#nav {
  /* font-family: 'Lucida Grande', 'Lucida Sans Unicode', 'Lucida Sans',
       Corbel, Arial, Helvetica, sans-serif; */
  font-family: Georgia, Helvetica, sans-serif;
  position: fixed;
  top: 50px;
  /* left: 860px; */
  margin-left: 860px;     /*1060*/
  width: 92px;
  font-size: 15px;
}

#nav li2 {
    margin-bottom: 1px;
}
ol {
  list-style: none;
}
#nav a {
    display: block;
    padding: 6px 9px 7px;
    color: #fff;
    background-color: #455A64;
    text-decoration: none;
}

#nav a:hover {
    color: #ffde00;
    /* background-color: #242d36 ; */
}
</style>

<!-- <script type="text/javascript" async="" src="./files/ga.js"></script>
<script type="text/javascript">
  var _gaq = _gaq || [];
  _gaq.push(['_setAccount', 'UA-7953909-1']);
  _gaq.push(['_trackPageview']);

  (function () {
    var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
    ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
    var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
  })();
</script> -->

<script type="text/javascript" src="./files/hidebib.js"></script>

<link href="http://fonts.googleapis.com/css?family=Lato:400,700,400italic,700italic" rel="stylesheet" type="text/css" /><!--<link href='http://fonts.googleapis.com/css?family=Open+Sans+Condensed:300' rel='stylesheet' type='text/css'>--><!--<link href='http://fonts.googleapis.com/css?family=Open+Sans' rel='stylesheet' type='text/css'>--><!--<link href='http://fonts.googleapis.com/css?family=Yanone+Kaffeesatz' rel='stylesheet' type='text/css'>-->
</head>
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');



</script>
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-66888300-1', 'auto');
  ga('send', 'pageview');

</script>

<!-- <script src="./files/main.js"></script> -->

<body>
  <ol id="nav">
    <li><a href="#home" title="Home">Home</a></li>
    <li><a href="#news" title="News">News</a></li>
    <li><a href="#pub" title="Papers">Papers</a></li>
    <li><a href="mailto:mdyao@mail.ustc.edu.cn" title="Contact">Contact</a></li>
  </ol>
<a name="home"></a>
<div style="margin-bottom: 1em; border: 1px solid #ddd; background-color: #fff; padding: 1em; height: 140px;">
<div style="margin: 0px auto; width: 100%;">
<img title="Mingde Yao (姚明德)" style="float: left; padding-left: .01em; height: 140px;" src="./fuji/mdyao_fuji.png" />
<div style="padding-left: 12em; vertical-align: top; height: 120px;"><span style="line-height: 150%; font-size: 20pt;">Mingde Yao (姚明德)</span><br />
<!-- <p>&nbsp;</p> -->
<p><a href="https://scholar.google.com/citations?user=fsE3MzwAAAAJ&hl=en">Google Scholar</a> &nbsp/&nbsp
  <a href="https://github.com/mdyao">Github</a> &nbsp/&nbsp
<!--   <a href="https://www.linkedin.com/in/%E6%96%87%E7%81%8F-%E5%90%B4-aab583128/?locale=en_US">Linkedin</a> &nbsp/&nbsp -->
  <a href="https://www.zhihu.com/people/you-men-de">Zhihu</a></p>
<p>&nbsp;</p>




<p><strong>Postdoctoral Researcher, <a href="https://www.cuhk.edu.hk/">The Chinese University of Hong Kong (CUHK)</a></strong><br />
<!-- <p><strong>Ph.D. Candidate, University of Science and Technology of China</strong><br /><br />
 --><!-- <p><strong>Senior R&D Engineer @ Baidu Inc.</strong><br /><br /> -->
  
<span><strong>School Email </strong>: mingdeyao (at) cuhk.edu.hk</span> <br />
<span><strong>Personal Email </strong>: mingdeyao (at) foxmail.com</span> <br />
</div>
</div>
</div>
<!--<div style="clear: both; background-color: #fff; margin-top: 1.5em; padding: .2em; padding-left: .3em;">-->

<div style="clear: both;">
<div class="section">
<!-- <h2>(<a href='https://scholar.google.com/citations?user=kWADCMUAAAAJ&hl=zh-CN'>Google scholar</a>)</h2> -->
<h2>About Me</h2>
<div class="bio">



Currently, I am a Postdoctoral Researcher at <a href="https://www.cuhk.edu.hk/">The Chinese University of Hong Kong (CUHK)</a>, advised by Prof. <a href="https://www.gujinwei.org/">Jinwei Gu</a> and  Prof. <a href="https://www.ee.cuhk.edu.hk/~hsli/">Hongsheng Li</a>. Before that, I obtained my Ph.D. degree from <a href="http://en.ustc.edu.cn/">University of Science and Technology of China (USTC)</a> in 2023, advised by Prof. <a href="http://staff.ustc.edu.cn/~zwxiong/">Zhiwei Xiong</a> and Prof. <a href="https://faculty.ustc.edu.cn/dongeliu/">Dong Liu</a>. I obtained my B. Eng. degree in the Department of Automation (Lang Shijun Honors Class) from Northeastern University (NEU, China) in 2018.


<!-- <br><br>
My research interests focus on computer vision, especially low-level vision tasks.
 -->
<br><br>
My research interests broadly lie in the areas of computational photography and deep learning (e.g., super-resolution, denoising, enhancement, high-dynamic-range imaging, and hyper-spectral image processing). I am recently interested in 3D reconstruction/generation.

<br><br>
<strong style="font-size:16px"> I am maintaining a GitHub repository named <a href="https://github.com/mdyao/Awesome-3D-AIGC/"> Awesome-3D-AIGC</a>, aiming to keep pace with the rapidly evolving 3D AIGC. If you have any additions or suggestions, feel free to contribute.</strong>
<!-- including <strong style="font-size:15px;color:#8aa371">low-level vision</strong> 
, 
<strong style="font-size:15px;color:#8aa371">Spectral image processing</strong>. -->
<!-- Recently, I have shifted my focus to 
<strong style="font-size:15px;color:#0294b9"></strong> (e.g., combining vision and language) and
<strong style="font-size:15px;color:#0294b9">AI Generated Content (AIGC)</strong>.
 -->

<!-- 
<br><br>
<strong style="font-size:16px">I will join <a href="https://www.cuhk.edu.hk/">The Chinese University of Hong Kong (CUHK)</a> as a Postdoctoral Researcher, advised by Prof. <a href="https://www.gujinwei.org/">Jinwei Gu</a> and  Prof. <a href="https://www.ee.cuhk.edu.hk/~hsli/">Hongsheng Li</a></strong>.



<br><br> -->


</div>
</div>


<a name="news"></a>
<div style="clear: both;">
<div class="section">
  <h2>Updates</h2>
  <div class="paper">
    <ul>

    <li><a class="button" href="#" style="color:#FFA500"><strong style="font-size:16px">New</strong></a> <strong
        style="padding-left:5px;">09/2023: </strong>
      <em> One paper is accepted by <strong><a href="https://nips.cc/">
            <font color="DarkRed">NeurIPS 2023</font></a></strong>.
        </em>
    </li>

    <li><a class="button" href="#" style="color:#FFA500"><strong style="font-size:16px">New</strong></a> <strong
        style="padding-left:5px;">07/2023: </strong>
      <em> One paper is accepted by <strong><a href="https://www.acmmm2023.org/">
            <font color="DarkRed">ACMMM 2023</font></a></strong>.
        </em>
    </li>

    <li><a class="button" href="#" style="color:#FFA500"><strong style="font-size:16px">New</strong></a> <strong
        style="padding-left:5px;">07/2023: </strong>
      <em> One paper is accepted by <strong><a href="https://iccv2023.thecvf.com/">
            <font color="DarkRed">ICCV 2023</font></a></strong>.
        </em>
    </li>



    <li> <a class="button" href="#" style="color:#FFA500"><strong style="font-size:16px">New</strong></a> <strong
        style="padding-left:5px;">02/2023: </strong>
      <em> Two papers are accepted by <strong><a href="https://cvpr2023.thecvf.com/">
            <font color="DarkRed">CVPR 2023</font></a></strong>.
        </em>
    </li>

    <li> <strong>02/2023: </strong>
      <em> One paper is accepted by  <strong><font color="DarkRed">T-CSVT</font></a></strong>.</em>
    </li>


    <li> <strong>01/2023: </strong>
      <em> One papers is accepted by
        <strong><font color="DarkRed">T-MM</font></a></strong>.</em>
    </li>

    <li> <strong>09/2022: </strong>
      <em> Our <a href="https://github.com/XrKang/NeSR">NeSR</a>, 
        the first work on implicit neural representation for spectral images, is accepted by
        <strong><a href="https://mipi-challenge.org/MIPI2022/">
            <font color="DarkRed">ECCVW 2022</font>,<font color="Gray"> Mobile Intelligent Photography & Imaging
Workshop</em></font>
          </a></strong>(<font color="Red"><b>Best Paper Honorable Mention</b></font>).</em>
    </li>


    <li> <strong>07/2022: </strong>
      <em> Three papers are accepted by 
        <strong>
            <font color="DarkRed">ACMMM</font></strong>.
        </em>
    </li>


    <li> <strong>03/2022: </strong>
      <em> One paper is accepted by 
        <strong>
            <font color="DarkRed">CVPR 2022</font></strong>.
        </em>
    </li>

    </ul>
  </div>
</div>
</div>






  <div style="clear: both;">
    <div class="section">
      <h2>Experience</h2>
      <div class="paper2">

<div class="education"><img class="education" src="logo/cuhk.png" />
          <div>
            <span style="font-size: 16px;" class="h1"></b>
              <b><a href="https://www.cuhk.edu.hk/">
                  <font color="Brown">The Chinese University of Hong Kong (CUHK)</font></a></b></span>
            <br>
            <p style="margin-top:6px;"><strong>Postdoctoral Researcher </strong>.
<!--               <br><em>Team: <a href='https://vidar-ustc.github.io//'>Visual Information Discovery And Recovery (VIDAR)</a></em>
 -->              <br><em>Advisors: Prof. <a href="https://www.gujinwei.org/">Jinwei Gu</a>, Prof. <a href="https://www.ee.cuhk.edu.hk/~hsli/">Hongsheng Li</a></em><br>
              2023 - now
            </p>
          </div>
        </div>


        <div class="education"><img class="education" src="logo/ustc.png" />
          <div>
            <span style="font-size: 16px;" class="h1"></b>
              <b><a href="https://www.ustc.edu.cn/">
                  <font color="Brown">University of Science and Technology of China</font></a></b></span>
            <br>
            <p style="margin-top:6px;"><strong>Doctor of Philosophy (Ph.D.) </strong> in ECE.
              <!-- <br><em>Team: <a href='https://vidar-ustc.github.io//'>Visual Information Discovery And Recovery (VIDAR)</a></em> -->
              <br><em>Advisors: Prof. <a href='http://staff.ustc.edu.cn/~zwxiong/'>Zhiwei Xiong</a>, Prof. <a href='https://faculty.ustc.edu.cn/dongeliu/'>Dong Liu</a></em><br>
              2018 - 2023
            </p>
          </div>
        </div>

 
  <div class="experience"><img class="experience" src="logo/baidu.png" />
    <div>
      <span style="font-size: 16px;" class="h1"></b>
      <b><a href="http://vis.baidu.com/">
        <font color="Brown">Baidu</font></a></b></span>
      <br>
      <p style="margin-top:6px;">Intern. on Image processing & Editing
        <br><em>worked with <a
          href="https://scholar.google.com/citations?user=ui6DYGoAAAAJ&hl=en">Dr. Dongliang He</a></em><br>
        Nov. 2021 - Dec. 2022 
      </p>
     </div>
  </div>
  
  
        <div class="education"><img class="education" src="logo/neu.png" />
          <div>
            <span style="font-size: 16px;" class="h1"></b>
              <b><a href="http://english.neu.edu.cn/">
                  <font color="Brown">Northeastern University</font></a>, China</b></span>
            <br>
            <p style="margin-top:6px;"><strong>Bachelor of Engineering</strong> in Automation (Lang Shijun Honors Class)
              <!-- <br><em>Advisors: <a href='http://mmlab.siat.ac.cn/sfchen'>Prof. Shifeng Chen</a>,
                <a href='http://mmlab.siat.ac.cn/yuqiao/'>Prof. Yu Qiao</a></em> while visiting CAS (Oct. 2016 - Jun. 2017)-->
                <br> 
              2014 - 2018
              <br> 
              <br> 
            </p>
          </div>
        </div>
    
      </div>
    </div>
  </div>


<!-- 
  <div style="clear: both;">
    <div class="section">
      <h2>Industrial Experience</h2>
      <div class="paper2">
 
  <div class="experience"><img class="experience" src="logo/baidu.png" />
    <div>
      <span style="font-size: 16px;" class="h1"></b>
      <b><a href="http://vis.baidu.com/">
        <font color="Brown">Baidu VIS</font></a></b></span>
      <br>
      <p style="margin-top:6px;">Intern. on Image processing & Editing
        <br><em>worked with <a
          href="https://scholar.google.com/citations?user=ui6DYGoAAAAJ&hl=en">Dr. Dongliang He</a></em><br>
        Nov. 2021 - Dec. 2022 
      </p>
     </div>
  </div>



      </div>
    </div>
  </div> -->





<a name="pub"></a>
<h2 id="confpapers">Selected Publications [ <a href="https://scholar.google.com/citations?user=fsE3MzwAAAAJ&hl=en">Full List</a> ] </h2>
<!--   [ <a href="http://whwu95.github.io/publication.html">Full List</a> ] </h2> -->
<!-- <b>( *Co-first Author, <sup><span lang="EN-US"
      style="mso-bidi-font-size:8pt;font-family:Wingdings;mso-ascii-font-family:'Times New Roman';mso-hansi-font-family:'Times New Roman';mso-char-type:symbol;mso-symbol-font-family:Wingdings">*</span></sup>Correspondence)</b> -->

<div class="section">
  <div class="bio">


    <!-- TIP23 -->
    <div class="paper" id="xxx"><img class="paper" src="papers/2023/DR-Restore.png" />
      <div>
        <a><b>Neural Degradation Representation Learning for All-In-One Image Restoration</b></a><br />
        <u><b style="color:darkred">Mingde Yao</b></u>, Ruikang Xu, Yuanshen Guan, Jie Huang, and Zhiwei Xiong.<br />
        <i>ArXiv preprint<b><font color="DarkRed"></font></b>, 2023</i><br />
        [ <a href='https://arxiv.org/pdf/2310.12848.pdf'>PDF</a> ]
        [ <a href='https://github.com/mdyao/NDR-Restore'>Code</a> ]

      </div>
      <div class="spanner"></div>
    </div>


    <!-- ACMMM23 -->
    <div class="paper" id="xxx"><img class="paper" src="papers/2023/MGDN.png" />
      <div>
        <a><b>Mutual-Guided Dynamic Network for Image Fusion</b></a><br />
        Yuanshen Guan, Ruikang Xu, <u><b style="color:darkred">Mingde Yao</b></u>, Lizhi Wang, and Zhiwei Xiong.<br />
        <i>ACM International Conference on Multimedia <b><font color="DarkRed">(ACMMM)</font></b>, 2023</i><br />
        [ <a href='https://arxiv.org/pdf/2308.12538.pdf'>PDF</a> ]
        [ <a href='https://github.com/guanys-dar/mgdn'>Code</a> ]

      </div>
      <div class="spanner"></div>
    </div>


    <!-- ICCV23 -->
    <div class="paper" id="xxx"><img class="paper" src="papers/2023/CSN.png" />
      <div>
        <a><b>Generalized Lightness Adaptation with Channel Selective Normalization</b></a><br />
        <u><b style="color:darkred">Mingde Yao</b></u>*, Jie Huang*, Xin Jin, Ruikang Xu, Shenglong Zhou, Man Zhou, and Zhiwei Xiong.<br />
        <i>IEEE International Conference on Computer Vision <b><font color="DarkRed">(ICCV)</font></b>, 2023</i><br />
        [ <a href='https://openaccess.thecvf.com/content/ICCV2023/papers/Yao_Generalized_Lightness_Adaptation_with_Channel_Selective_Normalization_ICCV_2023_paper.pdf'>PDF</a> ]
        [ <a href='https://github.com/mdyao/CSN-Net-ICCV2023'>Code</a> ]

      </div>
      <div class="spanner"></div>
    </div>

    <!-- CVPR23 -->
    <div class="paper" id="CVPR23"><img class="paper" src="papers/2023/ZeDuSR2.png" />
      <div>
        <a><b>Zero-Shot Dual-Lens Super-Resolution</b></a><br />
        Ruikang Xu*, <u><b style="color:darkred">Mingde Yao</b></u>*, and Zhiwei Xiong.<br />
        <i>IEEE Conference on Computer Vision and Pattern Recognition <b>
            <font color="DarkRed">(CVPR)</font>
          </b>, 2023 </i><br />
        [ <a href='https://openaccess.thecvf.com/content/CVPR2023/papers/Xu_Zero-Shot_Dual-Lens_Super-Resolution_CVPR_2023_paper.pdf'>PDF</a> ]
        [ <a href='https://github.com/XrKang/ZeDuSR'>Code</a> ]
        [ <a href='https://cvpr.thecvf.com/media/cvpr-2023/Slides/22470.pdf'>Slide</a> ]
        [ <a href='https://www.youtube.com/watch?v=ChHAIGyDFAI'>Video</a> ]
        <br />
      </div>
      <div class="spanner"></div>
    </div>


    <!-- CVPR23 -->
    <div class="paper" id="CVPR23"><img class="paper" src="papers/2023/IDR.png" />
      <div>
        <a><b>Ingredient-oriented Multi-Degradation Learning for Image Restoration</b></a><br />
        Jinghao Zhang, Jie Huang, <u><b style="color:darkred">Mingde Yao</b></u>, Zizheng Yang, Hu Yu, Man Zhou, and Feng Zhao.<br />
        <i>IEEE Conference on Computer Vision and Pattern Recognition <b>
            <font color="DarkRed">(CVPR)</font>
          </b>, 2023 </i><br />
        [ <a href='https://openaccess.thecvf.com/content/CVPR2023/papers/Zhang_Ingredient-Oriented_Multi-Degradation_Learning_for_Image_Restoration_CVPR_2023_paper.pdf'>PDF</a> ]
    [ <a shape="rect" href="javascript:togglebib(&#39;xxx1&#39;)" class="togglebib">Bibtex</a> ]<br />
    <pre xml:space="preserve" style="display: none;">
      @inproceedings{zhang2023ingredient,
      title={Ingredient-Oriented Multi-Degradation Learning for Image Restoration},
      author={Zhang, Jinghao and Huang, Jie and Yao, Mingde and Yang, Zizheng and Yu, Hu and Zhou, Man and Zhao, Feng},
      booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
      pages={5825--5835},
      year={2023}
      }
      </pre>
        <br />
      </div>
      <div class="spanner"></div>
    </div>


    <!-- TMM2023 -->
    <div class="paper" id="TMM2023"><img class="paper" src="papers/2023/BiTNet.gif" />
      <div>
        <a><b>Bidirectional Translation between HD-SDR and UHD-HDR Videos</b></a><br />
         <u><b style="color:darkred">Mingde Yao</b></u>, Dongliang He, Xin Li, Zhihong Pan, and Zhiwei Xiong.<br />
        <i>Transactions on Multimedia  <b>
            <font color="DarkRed">(T-MM)</font>
          </b>, 2023 </i><br />
        [ <a href='https://ieeexplore.ieee.org/abstract/document/10025794'>PDF</a> ]
        [ <a href='https://github.com/mdyao/HDR-BiTNet'>Code</a> ]
        <br />
      </div>
      <div class="spanner"></div>
    </div>




    <!-- TCSVT2023 -->
    <div class="paper" id="TCSVT2023"><img class="paper" src="papers/2023/self_inter_dn.png" />
      <div>
        <a><b>Towards Interactive Self-Supervised Denoising
</b></a><br />
         <u><b style="color:darkred">Mingde Yao</b></u>, Dongliang He, Xin Li, Fu Li, and Zhiwei Xiong.<br />
        <i> IEEE Transactions on Circuits and Systems for Video Technology <b>
            <font color="DarkRed">(T-CSVT)</font>
          </b>, 2023 </i><br />
        [ <a href='https://ieeexplore.ieee.org/abstract/document/10059001'>PDF</a> ]
        [ <a href='https://github.com/mdyao/Interact_Self_supervised_denoising'>Code</a> ]
    [ <a shape="rect" href="javascript:togglebib(&#39;TCSVT2023&#39;)" class="togglebib">Bibtex</a> ]<br />
    <pre xml:space="preserve" style="display: none;">
      @article{yao2023towards,
      title={Towards interactive self-supervised denoising},
      author={Yao, Mingde and He, Dongliang and Li, Xin and Li, Fu and Xiong, Zhiwei},
      journal={IEEE Transactions on Circuits and Systems for Video Technology},
      year={2023},
      publisher={IEEE}
      }
      </pre>


        <br />
      </div>
      <div class="spanner"></div>
    </div>

    <!-- CVPR2022 -->
    <div class="paper" id="ECCVW2022"><img class="paper" src="papers/2022/IdeSR.png" />
      <div>
        <a><b>Towards Bidirectional Arbitrary Image Rescaling: Joint Optimization and Cycle Idempotence
</b></a><br />
        Zhihong Pan, Baopu Li, Dongliang He, <u><b style="color:darkred">Mingde Yao</b></u>, Wenhao Wu, Tianwei Lin, Xin Li, and Errui Ding.<br />
        <i>  IEEE Conference on Computer Vision and Pattern Recognition <b>
            <font color="DarkRed">(CVPR)</font>
          </b>, 2022 </i><br /> 
        [ <a href='https://openaccess.thecvf.com/content/CVPR2022/papers/Pan_Towards_Bidirectional_Arbitrary_Image_Rescaling_Joint_Optimization_and_Cycle_Idempotence_CVPR_2022_paper.pdf'>PDF</a> ]
            [ <a shape="rect" href="javascript:togglebib(&#39;TCSVT2023&#39;)" class="togglebib">Bibtex</a> ]<br />
        <pre xml:space="preserve" style="display: none;">
        @inproceedings{pan2022towards,
        title={Towards bidirectional arbitrary image rescaling: Joint optimization and cycle idempotence},
        author={Pan, Zhihong and Li, Baopu and He, Dongliang and Yao, Mingde and Wu, Wenhao and Lin, Tianwei and Li, Xin and Ding, Errui},
        booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
        pages={17389--17398},
        year={2022}
        }
        </pre>

      </div>
      <div class="spanner"></div>
    </div>




    <!-- ECCVW2022 -->
    <div class="paper" id="ECCVW2022"><img class="paper" src="papers/2022/NeSR.png" />
      <div>
        <a><b>Continuous Spectral Reconstruction from RGB Images via Implicit Neural Representation
</b></a><br />
         Ruikang Xu, <u><b style="color:darkred">Mingde Yao</b></u>, Chang Chen, Lizhi Wang, and Zhiwei Xiong.<br />
        <i>ECCV <font color="Gray"> Mobile Intelligent Photography & Imaging
Workshop</em></font> <b>
            <font color="DarkRed">(ECCVW)</font>
          </b>, 2022 </i><br /> 
        </font><font color="Red"><b>[Best Paper Honorable Mention]</b></font><br /> 
        [ <a href='https://arxiv.org/pdf/2112.13003.pdf'>PDF</a> ]
        [ <a href='https://github.com/XrKang/NeSR'>Code</a> ]
        <br />
      </div>
      <div class="spanner"></div>
    </div>


  <!-- OE2019 -->
    <div class="paper" id="OE2019"><img class="paper" src="papers/2019/OE19.png" />
      <div>
        <a><b>Spectral-depth imaging with deep learning based reconstruction
</b></a><br />
         <u><b style="color:darkred">Mingde Yao</b></u>,  Zhiwei Xiong, Lizhi Wang, Dong Liu, and Xuejin Chen.<br />
        <i>Optics Express  <b>
            <font color="DarkRed">(OE)</font>
          </b>, 2019 </i><br /> 
        [ <a href='https://opg.optica.org/oe/fulltext.cfm?uri=oe-27-26-38312'>PDF</a> ]
      </div>
      <div class="spanner"></div>
    </div>



</div>
</div>










<div style="clear: both;">
<div class="section">
<h2 id="confpapers">Awards</h2>
<div class="paper">
<ul>
<!-- <li>The NTIRE Perceptual Extreme Super-Resolution Challenge on CVPR'20: Won 1st in SSIM, 2nd in PSNR, and 11th in LPIPS.</li> -->
<li><font color="Red"><b>National Scholarship</b></font> awarded by the Ministry of Education, 2015</li>
<li><font color="Red"><b>Outstanding Graduates</b></font> awarded by the Province Government, 2017</li>
<li><font color="Red"><b>Winner</b></font> of Bokeh Effect Synthesis in ICCV AIM Challenge, 2019 </li>
<li><font color="Blue"><b>Runner-Up</b></font> of Burst Super-Resolution in CVPR NTIRE Challenge, 2022</li>
<li><font color="Blue"><b>Second runner-up</b></font> of Atmospheric Turbulence Mitigation in CVPR UG+ Challenge, 2022</li>
<!-- <li><font color="DarkRed"><b>ICCV Doctoral Consortium</b></font>, 2023</li> -->



</ul>
<div class="spanner"></div>
</div>
</div>
</div>







<!-- <div style="clear: both;">
<div class="section"><h2>Awards</h2>
<div class="paper">
<h3>PhD:</h3>
<li><a href="https://good-design.org/projects/curbyit/">Australian Good Design Award</a></li>
<li> Faculty of Engineering Research Scholarship at the University of Sydney (<b>Tuition fees offsets + $37,207 p.a.</b>)</li>
<h3>Master:</h3>
<li> Baidu Best Newcomer, 2021</li>
<li> Excellent Student Cadre of University of Chinese Academy of Sciences, 2020
<li> Baidu Best Intern, 2019 </li>
<li> Scholarship for Academic Excellence of Shenzhen Institutes of Advanced Technology, CAS, 2018 </li>
<li> University of Chinese Academy of Sciences (UCAS) Scholarships (<b>16,000 RMB p.a.</b>), 2017-2020</li>
<h3>Undergraduate:</h3>
<li> Excellent Undergraduate Student of Central South University, 2017 </li>
<li> Outstanding Student of Central South University, 2016 </li>
<li> National Endeavor Scholarship (Top 5%), 2016 </li>
<li> Excellent National College Students Innovation and Entrepreneurship Project (20,000 RMB), 2016</li>
<li> Excellent Student Cadre of Central South University, 2015</li>
<li> Excellent League Member of Central South University, 2015</li>
<li> Scholarship for Academic Excellence of Central South University, 2014/2015/2016</li>

</div>
</div>
</div> -->

  
<div style="clear: both;">
<div class="section"><h2>Academic Activities</h2>
<div class="paper">
<h3>Reviewer</h3>
<li>T-PAMI, IJCV, CVPR, ICCV, ECCV, NeurIPS, ICLR, ICML, AAAI, ACMMM, IJCAI</li>

<!-- <h3>Member of IEEE, ACM, AAAI and CVF</h3> -->

</div>
</div>
</div>  

<!-- 
<div style="clear: both;">
  <div class="section">
    <h2>Current/Past Mentoring</h2>
    <div class="paper">
      <a href=''>Yuxiang Zhao</a> (Peking University),

    </div>
  </div>
</div>

<div style="clear: both;">
<div class="section"><h2>Collaborators & Friends</h2>
<div class="paper">
<a href=''>Chang Liu</a> (Tsinghua University),
 -->





</div>
</div>
</div>


<div style="clear:both;">
<p align="right"><font size="5">Last Updated in July, 2023</a></font></p>
<p align="right"><font size="5">Published with <a href='https://pages.github.com/'>GitHub Pages</a></font></p>
</div>

<hr>
<div id="clustrmaps-widget"></div><script type='text/javascript' id='clustrmaps' src='//cdn.clustrmaps.com/map_v2.js?cl=7878ad&w=268&t=n&d=Oiyd_ZsSxaiYwrp_EYx0zILMmpUPf8-9re9sJssfxww&co=ccdaea&ct=808080&cmo=3acc3a&cmn=ff5353'></script>

</body>
</html>
